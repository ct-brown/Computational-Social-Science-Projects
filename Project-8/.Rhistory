# Add to this package list for additional SL algorithms
pacman::p_load(
tidyverse,
ggthemes,
ltmle,
tmle,
SuperLearner,
tidymodels,
caret,
dagitty,
ggdag,
here)
heart_disease <- read_csv(here('Project-8/heart_disease_tmle.csv'))
source("pretty_dag.R")
# Fit SuperLearner Model
## sl lib
lib <- c("SL.glm", "SL.randomForest", "SL.xgboost", "SL.svm", "SL.nnet")
## Train/Test split
### initial split
heart_split <- initial_split(heart_disease, prop = 3/4)
### Training
train <- training(heart_split)
#### y_train
y_train <- train %>%
pull(mortality)
#### x_train
x_train <- train %>%
select(-mortality)
### Testing
test <- testing(heart_split)
#### y test
y_test <- test %>%
pull(mortality)
#### x test
x_test <- test %>%
select(-mortality)
## Train SuperLearner
### set seed
set.seed(123)
sl = SuperLearner(Y = y_train,
X = x_train,
family = binomial(),
SL.library = lib)
## Risk and Coefficient of each model
sl
## Discrete winner and superlearner ensemble performance
sl # it looks like randomForest had the lowest risk score
#### predictions
preds <- predict(sl,
x_test,
onlySL = TRUE)
### validation
validation <- y_test %>%
bind_cols(preds$pred[,1]) %>%
rename(obs = `...1`,
pred = `...2`) %>%
mutate(pred = ifelse(pred >= .5,
1,
0))
## Risk and Coefficient of each model
sl
## Confusion Matrix
caret::confusionMatrix(as.factor(validation$pred),
as.factor(validation$obs))
# DAG for TMLE
## Y ~ mortality
## A ~ blood_pressure_medication
## W ~ age + sex_at_birth + simplified_race + college_educ + income_thousands + bmi + blood_pressure + chol
dag <- dagify(Y ~ A + W + U,
A ~ W + U,
W ~ U,
exposure = "A",
outcome = "Y") %>%
tidy_dagitty() %>%
pretty_dag()
dag %>%
ggdag() +
geom_dag_node(aes(color = color)) +
geom_dag_text(col = "white") +
theme(legend.position = "none") +
scale_color_manual(values=c("red","grey", "blue", "purple"))
# TMLE Estimation
set.seed(123)
Y <- heart_disease$mortality
A <- heart_disease$blood_pressure_medication
W <- heart_disease %>%
select(age, sex_at_birth, simplified_race, college_educ, income_thousands, bmi, blood_pressure, chol)
tmle_fit <-
tmle::tmle(Y = Y,
A = A,
W = W,
Q.SL.library = lib,
g.SL.library = lib)
# view results
tmle_fit
# Fit SuperLearner Model
## sl lib
lib <- c("SL.glm", "SL.randomForest", "SL.xgboost", "SL.svm", "SL.nnet")
## Train/Test split
### initial split
heart_split <- initial_split(heart_disease, prop = 3/4)
# Add to this package list for additional SL algorithms
pacman::p_load(
tidyverse,
ggthemes,
ltmle,
tmle,
SuperLearner,
tidymodels,
caret,
dagitty,
ggdag,
here)
heart_disease <- read_csv(here('Project-8/heart_disease_tmle.csv'))
source("pretty_dag.R")
# DAG for TMLE
dag <- dagify(Y ~ A0 + W0 + A1 + W1 + U,
A1 ~ W0 + A0 + U,
W1 ~ W0 + U,
A0 ~ W0 + U,
W0 ~ U,
exposure = "A1",
outcome = "Y") %>%
tidy_dagitty() %>%
pretty_dag()
# DAG for TMLE
dag <- dagify(Y ~ A0 + W0 + A1 + W1 + U,
A1 ~ W0 + A0 + U,
W1 ~ W0 + U,
A0 ~ W0 + U,
W0 ~ U,
exposure = "A1",
outcome = "Y") %>%
tidy_dagitty()
dag %>%
ggdag() +
geom_dag_node(aes(color = color)) +
geom_dag_text(col = "white") +
theme(legend.position = "none")
View(dag)
# DAG for TMLE
## Y ~ mortality
## A ~ blood_pressure_medication
## W ~ age + sex_at_birth + simplified_race + college_educ + income_thousands + bmi + blood_pressure + chol
dag <- dagify(Y ~ A + W + U,
A ~ W + U,
W ~ U,
exposure = "A",
outcome = "Y") %>%
tidy_dagitty() %>%
pretty_dag()
dag %>%
ggdag() +
geom_dag_node(aes(color = color)) +
geom_dag_text(col = "white") +
theme(legend.position = "none") +
scale_color_manual(values=c("red","grey", "blue", "purple"))
# DAG for TMLE
## I couldn't get dagify to work correctly with the wrapper, so I just drew the dag.
knitr::include_graphics("DAG.pdf")
colnames(heart_disease)
## Naive Model (no time-dependent confounding) estimate
dt.ltmle <- heart_disease %>%
rename(W0.1 = age,
W0.2 = sex_at_birth,
W0.3 = simplified_race,
W0.4 = college_educ,
W0.5 = income_thousands,
W0.6 = bmi,
W0.7 = blood_pressure,
W0.8 = chol,
A0 = blood_pressure_medication,
W1.1 = bmi_2,
W1.2 = blood_pressure_2,
W1.3 = chol_2,
A1 = blood_pressure_medication_2,
Y = mortality) %>%
select(W0.1, W0.2, W0.3, W0.4, W0.5, W0.6, W0.7, W0.8, A0, W1.1, W1.2, W1.3, A1, Y)
?ltmle
dt.ltmle.naive <- dt.ltmle %>%
select(W0.1, W0.2, W0.3, W0.4, W0.5, W0.6, W0.7, W0.8, A0, Y)
result.ltmle.naive <- ltmle(dt.ltmle.naive,
Anodes = "A0",
Ynodes = "Y",
abar = 1)
## sl lib
lib <- c("SL.glm", "SL.randomForest", "SL.xgboost", "SL.svm", "SL.nnet")
result.ltmle.naive <- ltmle(dt.ltmle.naive,
Anodes = "A0",
Ynodes = "Y",
abar = 1,
SL.library = lib)
install.packages("randomForest")
result.ltmle.naive <- ltmle(dt.ltmle.naive,
Anodes = "A0",
Ynodes = "Y",
abar = 1,
SL.library = lib)
install.packages("xgboost")
result.ltmle.naive <- ltmle(dt.ltmle.naive,
Anodes = "A0",
Ynodes = "Y",
abar = 1,
SL.library = lib)
install.packages("svm")
## sl lib
lib <- c("SL.glm", "SL.ridge", "SL.randomForest", "SL.xgboost", "SL.nnet")
result.ltmle.naive <- ltmle(dt.ltmle.naive,
Anodes = "A0",
Ynodes = "Y",
abar = 1,
SL.library = lib)
## sl lib
lib <- c("SL.glm", "SL.randomForest", "SL.xgboost", "SL.nnet", "SL.caret")
result.ltmle.naive <- ltmle(dt.ltmle.naive,
Anodes = "A0",
Ynodes = "Y",
abar = 1,
SL.library = lib)
result.ltmle.naive
# Longitudinal Model
result.ltmle.long <- ltmle(dt.ltmle,
Anodes = c("A0", "A1"),
Lnodes = c("W0.1", "W0.2", "W0.3", "W0.4", "W0.5", "W0.6", "W0.7", "W0.8", "W1.1", "W1.2", "W1.3"),
Ynodes = "Y",
abar = c(1, 1),
SL.library = lib)
